{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utilities import *\n",
    "from lib.experiments.an4_speech_encoder_decoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = HYPERPARAMETERS({\n",
    "    'EXPERIMENT': 'AN4',\n",
    "    'DESCRIPTION': 'Sequence To Sequence model',\n",
    "    'TIMESTAMP': HYPERPARAMETERS.create_timestamp(),\n",
    "\n",
    "    'MODEL_NAME': 'AN4_SPEECH_ENCODER_DECODER',\n",
    "\n",
    "    'PRELOAD_MODEL_PATH': None,  # 'AN4_STS_NewNew_no_augmentation.tar',\n",
    "\n",
    "    'ROOT_DIR': '/Volumes/SSD1',\n",
    "    'MANIFESTS': ['manifest.json'],  # , 'sts_manifest_pseudo.json'],\n",
    "\n",
    "    'TARGET_ENCODING': 'sts',  # ' ctc\n",
    "\n",
    "    'BATCH_SIZE': 20,\n",
    "    'NUM_WORKERS': 8,\n",
    "\n",
    "    'RNN_HIDDEN_SIZE': 256,\n",
    "    'RNN_NUM_LAYERS': 2,\n",
    "    'RNN_DROPOUT': 0.5,\n",
    "    'CNN_DROPOUT': 0.5,\n",
    "    'BIDIRECTIONAL': True,\n",
    "\n",
    "    'LR': 0.0003,\n",
    "    'LR_LAMBDA': lambda epoch: max(math.pow(0.78, math.floor((1 + epoch) / 200.0)), 0.01),\n",
    "    'WEIGHT_DECAY': 0,\n",
    "    'MOMENTUM': 0.9,\n",
    "    'NESTEROV': True,\n",
    "\n",
    "    'TEACHER_FORCING_RATIO': 0.5,\n",
    "\n",
    "    'LABEL_SMOOTHING' : 0.2,\n",
    "\n",
    "    'MAX_GRAD_NORM': 400,\n",
    "\n",
    "    'MAX_EPOCHS': 200,\n",
    "\n",
    "    'STOPPING_PATIENCE': 80,\n",
    "\n",
    "    'CHECKPOINT_INTERVAL': 10,\n",
    "    'CHECKPOINT_RESTORE': False,\n",
    "\n",
    "    'USE_CUDA': torch.cuda.is_available(),\n",
    "\n",
    "    'SEED': 123456,\n",
    "\n",
    "    'DATASET_MEAN_STD': (0.060487103, 0.16884679),\n",
    "\n",
    "    'NORMALIZE_DB': -40,\n",
    "    'NORMALIZE_MAX_GAIN': 300,\n",
    "\n",
    "    'MIN_MAX_AUDIO_DURATION': None,  # (1, 15),\n",
    "    'MIN_MAX_TRANSCRIPT_LEN': None,  # (0, 15),\n",
    "    'MIN_TRANSCRIPT_CONFIDENCE': None,  # 0.95,\n",
    "\n",
    "    'AUDIO_SAMPLE_RATE': 16000,\n",
    "\n",
    "    'SPECT_WINDOW_SIZE': 0.02,\n",
    "    'SPECT_WINDOW_STRIDE': 0.01,\n",
    "    'SPECT_WINDOW': 'hamming',\n",
    "\n",
    "    'AUGMENTATION_PROBABILITY': 0.0,\n",
    "\n",
    "    'NOISE_BG_PROBABILITY': 0.4,\n",
    "    'NOISE_BG_LEVELS': (0.0, 0.5),\n",
    "    'NOISE_BG_DIR': '/Volumes/SSD1/BACKGROUND_NOISE',\n",
    "\n",
    "    'AUDIO_PITCH_PROBABILITY': 0.4,\n",
    "    'AUDIO_PITCH_PM': 4,\n",
    "\n",
    "    'AUDIO_SPEED_PROBABILITY': 0.4,\n",
    "    'AUDIO_SPEED_LOW_HIGH': (0.9, 1.1),\n",
    "\n",
    "    'AUDIO_DYNAMIC_PROBABILITY': 0.4,\n",
    "    'AUDIO_DYNAMIC_LOW_HIGH': (0.5, 1.1),\n",
    "\n",
    "    'AUDIO_SHIFT_PROBABILITY': 0.4,\n",
    "    'AUDIO_SHIFT_MIN_MAX': (-10, 10),\n",
    "\n",
    "    'AUDIO_NOISE_PROBABILITY': 0.4,\n",
    "    'AUDIO_NOISE_LEVELS': (0.0, 0.5),\n",
    "    'AUDIO_NOISE_COLORS': ['white', 'pink', 'blue', 'brown', 'violet'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 17:47:37,390 | INFO : Training start.\n",
      "2019-02-03 17:47:37,392 | INFO : {\n",
      "    'EXPERIMENT'                    : 'AN4' ,\n",
      "    'DESCRIPTION'                   : 'Sequence To Sequence model' ,\n",
      "    'TIMESTAMP'                     : '2019-02-03-17-47-37-000037' ,\n",
      "    'MODEL_NAME'                    : 'AN4_SPEECH_ENCODER_DECODER_1st' ,\n",
      "    'PRELOAD_MODEL_PATH'            : None ,\n",
      "    'ROOT_DIR'                      : '/Volumes/SSD1' ,\n",
      "    'MANIFESTS'                     : ['manifest.json'] ,\n",
      "    'TARGET_ENCODING'               : 'sts' ,\n",
      "    'BATCH_SIZE'                    : 20 ,\n",
      "    'NUM_WORKERS'                   : 8 ,\n",
      "    'RNN_HIDDEN_SIZE'               : 256 ,\n",
      "    'RNN_NUM_LAYERS'                : 2 ,\n",
      "    'RNN_DROPOUT'                   : 0.5 ,\n",
      "    'CNN_DROPOUT'                   : 0.5 ,\n",
      "    'BIDIRECTIONAL'                 : True ,\n",
      "    'LR'                            : 0.0003 ,\n",
      "    'LR_LAMBDA': lambda epoch: max(math.pow(0.78, math.floor((1 + epoch) / 200.0)), 0.01),\n",
      "    'WEIGHT_DECAY'                  : 0 ,\n",
      "    'MOMENTUM'                      : 0.9 ,\n",
      "    'NESTEROV'                      : True ,\n",
      "    'TEACHER_FORCING_RATIO'         : 0.5 ,\n",
      "    'LABEL_SMOOTHING'               : 0.2 ,\n",
      "    'MAX_GRAD_NORM'                 : 400 ,\n",
      "    'MAX_EPOCHS'                    : 200 ,\n",
      "    'STOPPING_PATIENCE'             : 80 ,\n",
      "    'CHECKPOINT_INTERVAL'           : 10 ,\n",
      "    'CHECKPOINT_RESTORE'            : False ,\n",
      "    'USE_CUDA'                      : True ,\n",
      "    'SEED'                          : 123456 ,\n",
      "    'DATASET_MEAN_STD'              : (0.060487103, 0.16884679) ,\n",
      "    'NORMALIZE_DB'                  : -40 ,\n",
      "    'NORMALIZE_MAX_GAIN'            : 300 ,\n",
      "    'MIN_MAX_AUDIO_DURATION'        : None ,\n",
      "    'MIN_MAX_TRANSCRIPT_LEN'        : None ,\n",
      "    'MIN_TRANSCRIPT_CONFIDENCE'     : None ,\n",
      "    'AUDIO_SAMPLE_RATE'             : 16000 ,\n",
      "    'SPECT_WINDOW_SIZE'             : 0.02 ,\n",
      "    'SPECT_WINDOW_STRIDE'           : 0.01 ,\n",
      "    'SPECT_WINDOW'                  : 'hamming' ,\n",
      "    'AUGMENTATION_PROBABILITY'      : 0.0 ,\n",
      "    'NOISE_BG_PROBABILITY'          : 0.4 ,\n",
      "    'NOISE_BG_LEVELS'               : (0.0, 0.5) ,\n",
      "    'NOISE_BG_DIR'                  : '/Volumes/SSD1/BACKGROUND_NOISE' ,\n",
      "    'AUDIO_PITCH_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_PITCH_PM'                : 4 ,\n",
      "    'AUDIO_SPEED_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_SPEED_LOW_HIGH'          : (0.9, 1.1) ,\n",
      "    'AUDIO_DYNAMIC_PROBABILITY'     : 0.4 ,\n",
      "    'AUDIO_DYNAMIC_LOW_HIGH'        : (0.5, 1.1) ,\n",
      "    'AUDIO_SHIFT_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_SHIFT_MIN_MAX'           : (-10, 10) ,\n",
      "    'AUDIO_NOISE_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_NOISE_LEVELS'            : (0.0, 0.5) ,\n",
      "    'AUDIO_NOISE_COLORS'            : ['white', 'pink', 'blue', 'brown', 'violet'] ,\n",
      "}\n",
      "\n",
      "2019-02-03 17:47:37,399 | INFO : AudioDataset\n",
      "    Total of datapoints: 948\n",
      "    Total of duration (min): 42.438333333333425\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioAugmentation [\n",
      "   AudioNoiseInjection(probability=0.4, noise_levels=(0.0, 0.5), noise_dir/Volumes/SSD1/BACKGROUND_NOISE),\n",
      "   AudioNoiseGeneration(probability=0.4, noise_levels=(0.0, 0.5), noise_colors['white', 'pink', 'blue', 'brown', 'violet']),\n",
      "   AudioPitchShift(probability=0.4, sample_rate=16000, pitch_pm=4),\n",
      "   AudioTimeStrech(probability=0.4, low_high=(0.9, 1.1)),\n",
      "   AudioDynamicRange(probability=0.4, low_high=(0.5, 1.1)),\n",
      "   AudioTimeShift(probability=0.4, sample_rate=16000, min_max=(-10, 10))\n",
      "], probability=0.0)\n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 17:47:37,405 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 17:47:37,406 | INFO : AudioDataset\n",
      "    Total of datapoints: 948\n",
      "    Total of duration (min): 42.438333333333425\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioAugmentation [\n",
      "   AudioNoiseInjection(probability=0.4, noise_levels=(0.0, 0.5), noise_dir/Volumes/SSD1/BACKGROUND_NOISE),\n",
      "   AudioNoiseGeneration(probability=0.4, noise_levels=(0.0, 0.5), noise_colors['white', 'pink', 'blue', 'brown', 'violet']),\n",
      "   AudioPitchShift(probability=0.4, sample_rate=16000, pitch_pm=4),\n",
      "   AudioTimeStrech(probability=0.4, low_high=(0.9, 1.1)),\n",
      "   AudioDynamicRange(probability=0.4, low_high=(0.5, 1.1)),\n",
      "   AudioTimeShift(probability=0.4, sample_rate=16000, min_max=(-10, 10))\n",
      "], probability=0.0)\n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 17:47:37,407 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 17:47:40,615 | INFO : Summary for model: NeuralSpeechRecognizer\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Shape                                   Param #        \n",
      "====================================================================================================\n",
      "cnn.conv1.seq_module.0 (Conv2d)              ((32, 1, 41, 11),)                      14432          \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.1 (BatchNorm2d)         ((32,), (32,))                          64             \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.2 (Hardtanh)            ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.3 (Dropout)             ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.0 (Conv2d)              ((32, 32, 21, 11),)                     236544         \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.1 (BatchNorm2d)         ((32,), (32,))                          64             \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.2 (Hardtanh)            ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.3 (Dropout)             ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "enc.rnn.rnn (GRU)                            ((768, 1312), (768, 256), (768,), (768, 3594240        \n",
      "____________________________________________________________________________________________________\n",
      "dec.embedding.0 (Embedding)                  ((32, 512),)                            16384          \n",
      "____________________________________________________________________________________________________\n",
      "dec.embedding.1 (Dropout)                    ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "dec.attn.linear_out (Linear)                 ((512, 1024), (512,))                   524800         \n",
      "____________________________________________________________________________________________________\n",
      "dec.rnn (GRU)                                ((1536, 512), (1536, 512), (1536,), (15 3151872        \n",
      "____________________________________________________________________________________________________\n",
      "dec.fc (Linear)                              ((32, 512), (32,))                      16416          \n",
      "====================================================================================================\n",
      "Total params:         7,555,840\n",
      "Trainable params:     7,555,840\n",
      "____________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 19:13:23,927 | INFO : TensorboardLogger\n",
      "    Last Epoch/LR:    200 / 0.000234\n",
      "    Train Loss/Score: 0.26588307654304344 / 0.9958874927229358\n",
      "    Valid Loss/Score: 14.401549001840445 / 0.8841775425429271\n",
      "    Best Epoch/Score: 171 / 0.901217436409744\n",
      "\n",
      "2019-02-03 19:13:23,937 | INFO : Stopping\n",
      "    Patience: 80\n",
      "    Best Score: 0.9012\n",
      "    Epoch of Best Score: 171\n",
      "\n",
      "2019-02-03 19:13:23,938 | INFO : Checkpoint\n",
      "    Timestamp: 2019-02-03-19-13-23-000023\n",
      "    Last Checkpoint: AN4/chkpt/2019-02-03-17-47-37-000037/2019-02-03-19-13-23-000023/state.tar\n",
      "\n",
      "2019-02-03 19:13:23,939 | INFO : Training end.\n"
     ]
    }
   ],
   "source": [
    "H.MODEL_NAME = 'AN4_SPEECH_ENCODER_DECODER_1st'\n",
    "\n",
    "run_training(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.MODEL_NAME = 'AN4_SPEECH_ENCODER_DECODER_1st'\n",
    "\n",
    "from lib.models.speech_encoder_decoder import *\n",
    "from lib.vocabulary import Vocabulary\n",
    "\n",
    "vocab = Vocabulary(os.path.join(H.ROOT_DIR, H.EXPERIMENT), encoding=H.TARGET_ENCODING)\n",
    "\n",
    "model = NeuralSpeechRecognizer(vocab, 50, rnn_hidden_size=H.RNN_HIDDEN_SIZE,\n",
    "                                   rnn_num_layers=H.RNN_NUM_LAYERS, rnn_dropout=H.RNN_DROPOUT,\n",
    "                                   cnn_dropout=H.CNN_DROPOUT,\n",
    "                                   teacher_forcing_ratio=H.TEACHER_FORCING_RATIO,\n",
    "                                   sample_rate=H.AUDIO_SAMPLE_RATE, window_size=H.SPECT_WINDOW_SIZE,\n",
    "                                   initialize=torch_weight_init)\n",
    "\n",
    "state = torch.load(os.path.join(H.EXPERIMENT, H.MODEL_NAME + '.tar'))\n",
    "model.load_state_dict(state)\n",
    "\n",
    "\n",
    "new_model = NeuralSpeechRecognizer(vocab, 50, rnn_hidden_size=H.RNN_HIDDEN_SIZE,\n",
    "                                   rnn_num_layers=H.RNN_NUM_LAYERS, rnn_dropout=H.RNN_DROPOUT,\n",
    "                                   cnn_dropout=H.CNN_DROPOUT,\n",
    "                                   teacher_forcing_ratio=H.TEACHER_FORCING_RATIO,\n",
    "                                   sample_rate=H.AUDIO_SAMPLE_RATE, window_size=H.SPECT_WINDOW_SIZE,\n",
    "                                   initialize=torch_weight_init)\n",
    "\n",
    "new_model.enc = model.enc\n",
    "\n",
    "torch.save(new_model.state_dict(), os.path.join(H.EXPERIMENT, H.MODEL_NAME + '.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 19:13:24,251 | INFO : Training start.\n",
      "2019-02-03 19:13:24,253 | INFO : {\n",
      "    'EXPERIMENT'                    : 'AN4' ,\n",
      "    'DESCRIPTION'                   : 'Sequence To Sequence model' ,\n",
      "    'TIMESTAMP'                     : '2019-02-03-17-47-37-000037' ,\n",
      "    'MODEL_NAME'                    : 'AN4_SPEECH_ENCODER_DECODER_2nd' ,\n",
      "    'PRELOAD_MODEL_PATH'            : 'AN4_SPEECH_ENCODER_DECODER_1st.tar' ,\n",
      "    'ROOT_DIR'                      : '/Volumes/SSD1' ,\n",
      "    'MANIFESTS'                     : ['manifest.json'] ,\n",
      "    'TARGET_ENCODING'               : 'sts' ,\n",
      "    'BATCH_SIZE'                    : 20 ,\n",
      "    'NUM_WORKERS'                   : 8 ,\n",
      "    'RNN_HIDDEN_SIZE'               : 256 ,\n",
      "    'RNN_NUM_LAYERS'                : 2 ,\n",
      "    'RNN_DROPOUT'                   : 0.5 ,\n",
      "    'CNN_DROPOUT'                   : 0.5 ,\n",
      "    'BIDIRECTIONAL'                 : True ,\n",
      "    'LR'                            : 0.0003 ,\n",
      "    'LR_LAMBDA': lambda epoch: max(math.pow(0.78, math.floor((1 + epoch) / 200.0)), 0.01),\n",
      "    'WEIGHT_DECAY'                  : 0 ,\n",
      "    'MOMENTUM'                      : 0.9 ,\n",
      "    'NESTEROV'                      : True ,\n",
      "    'TEACHER_FORCING_RATIO'         : 0.5 ,\n",
      "    'LABEL_SMOOTHING'               : 0.2 ,\n",
      "    'MAX_GRAD_NORM'                 : 400 ,\n",
      "    'MAX_EPOCHS'                    : 200 ,\n",
      "    'STOPPING_PATIENCE'             : 80 ,\n",
      "    'CHECKPOINT_INTERVAL'           : 10 ,\n",
      "    'CHECKPOINT_RESTORE'            : False ,\n",
      "    'USE_CUDA'                      : True ,\n",
      "    'SEED'                          : 123456 ,\n",
      "    'DATASET_MEAN_STD'              : (0.060487103, 0.16884679) ,\n",
      "    'NORMALIZE_DB'                  : -40 ,\n",
      "    'NORMALIZE_MAX_GAIN'            : 300 ,\n",
      "    'MIN_MAX_AUDIO_DURATION'        : None ,\n",
      "    'MIN_MAX_TRANSCRIPT_LEN'        : None ,\n",
      "    'MIN_TRANSCRIPT_CONFIDENCE'     : None ,\n",
      "    'AUDIO_SAMPLE_RATE'             : 16000 ,\n",
      "    'SPECT_WINDOW_SIZE'             : 0.02 ,\n",
      "    'SPECT_WINDOW_STRIDE'           : 0.01 ,\n",
      "    'SPECT_WINDOW'                  : 'hamming' ,\n",
      "    'AUGMENTATION_PROBABILITY'      : 0.0 ,\n",
      "    'NOISE_BG_PROBABILITY'          : 0.4 ,\n",
      "    'NOISE_BG_LEVELS'               : (0.0, 0.5) ,\n",
      "    'NOISE_BG_DIR'                  : '/Volumes/SSD1/BACKGROUND_NOISE' ,\n",
      "    'AUDIO_PITCH_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_PITCH_PM'                : 4 ,\n",
      "    'AUDIO_SPEED_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_SPEED_LOW_HIGH'          : (0.9, 1.1) ,\n",
      "    'AUDIO_DYNAMIC_PROBABILITY'     : 0.4 ,\n",
      "    'AUDIO_DYNAMIC_LOW_HIGH'        : (0.5, 1.1) ,\n",
      "    'AUDIO_SHIFT_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_SHIFT_MIN_MAX'           : (-10, 10) ,\n",
      "    'AUDIO_NOISE_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_NOISE_LEVELS'            : (0.0, 0.5) ,\n",
      "    'AUDIO_NOISE_COLORS'            : ['white', 'pink', 'blue', 'brown', 'violet'] ,\n",
      "}\n",
      "\n",
      "2019-02-03 19:13:24,260 | INFO : AudioDataset\n",
      "    Total of datapoints: 948\n",
      "    Total of duration (min): 42.438333333333425\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioAugmentation [\n",
      "   AudioNoiseInjection(probability=0.4, noise_levels=(0.0, 0.5), noise_dir/Volumes/SSD1/BACKGROUND_NOISE),\n",
      "   AudioNoiseGeneration(probability=0.4, noise_levels=(0.0, 0.5), noise_colors['white', 'pink', 'blue', 'brown', 'violet']),\n",
      "   AudioPitchShift(probability=0.4, sample_rate=16000, pitch_pm=4),\n",
      "   AudioTimeStrech(probability=0.4, low_high=(0.9, 1.1)),\n",
      "   AudioDynamicRange(probability=0.4, low_high=(0.5, 1.1)),\n",
      "   AudioTimeShift(probability=0.4, sample_rate=16000, min_max=(-10, 10))\n",
      "], probability=0.0)\n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 19:13:24,267 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 19:13:24,268 | INFO : AudioDataset\n",
      "    Total of datapoints: 948\n",
      "    Total of duration (min): 42.438333333333425\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioAugmentation [\n",
      "   AudioNoiseInjection(probability=0.4, noise_levels=(0.0, 0.5), noise_dir/Volumes/SSD1/BACKGROUND_NOISE),\n",
      "   AudioNoiseGeneration(probability=0.4, noise_levels=(0.0, 0.5), noise_colors['white', 'pink', 'blue', 'brown', 'violet']),\n",
      "   AudioPitchShift(probability=0.4, sample_rate=16000, pitch_pm=4),\n",
      "   AudioTimeStrech(probability=0.4, low_high=(0.9, 1.1)),\n",
      "   AudioDynamicRange(probability=0.4, low_high=(0.5, 1.1)),\n",
      "   AudioTimeShift(probability=0.4, sample_rate=16000, min_max=(-10, 10))\n",
      "], probability=0.0)\n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 19:13:24,269 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 19:13:24,375 | INFO : Summary for model: NeuralSpeechRecognizer\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Shape                                   Param #        \n",
      "====================================================================================================\n",
      "cnn.conv1.seq_module.0 (Conv2d)              ((32, 1, 41, 11),)                      14432          \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.1 (BatchNorm2d)         ((32,), (32,))                          64             \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.2 (Hardtanh)            ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.3 (Dropout)             ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.0 (Conv2d)              ((32, 32, 21, 11),)                     236544         \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.1 (BatchNorm2d)         ((32,), (32,))                          64             \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.2 (Hardtanh)            ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.3 (Dropout)             ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "enc.rnn.rnn (GRU)                            ((768, 1312), (768, 256), (768,), (768, 3594240        \n",
      "____________________________________________________________________________________________________\n",
      "dec.embedding.0 (Embedding)                  ((32, 512),)                            16384          \n",
      "____________________________________________________________________________________________________\n",
      "dec.embedding.1 (Dropout)                    ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "dec.attn.linear_out (Linear)                 ((512, 1024), (512,))                   524800         \n",
      "____________________________________________________________________________________________________\n",
      "dec.rnn (GRU)                                ((1536, 512), (1536, 512), (1536,), (15 3151872        \n",
      "____________________________________________________________________________________________________\n",
      "dec.fc (Linear)                              ((32, 512), (32,))                      16416          \n",
      "====================================================================================================\n",
      "Total params:         7,555,840\n",
      "Trainable params:     7,555,840\n",
      "____________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 19:13:24,426 | INFO : Preloaded model: AN4/AN4_SPEECH_ENCODER_DECODER_1st.tar\n",
      "2019-02-03 20:23:30,886 | INFO : Early stopping at epoch: 82, score 0.930966\n",
      "2019-02-03 20:23:31,137 | INFO : TensorboardLogger\n",
      "    Last Epoch/LR:    163 / 0.0003\n",
      "    Train Loss/Score: 0.27625186282371167 / 0.9945111703814236\n",
      "    Valid Loss/Score: 11.992471900353065 / 0.8974900526823604\n",
      "    Best Epoch/Score: 82 / 0.9309660318314165\n",
      "\n",
      "2019-02-03 20:23:31,138 | INFO : Stopping\n",
      "    Patience: 80\n",
      "    Best Score: 0.9310\n",
      "    Epoch of Best Score: 82\n",
      "\n",
      "2019-02-03 20:23:31,140 | INFO : Checkpoint\n",
      "    Timestamp: 2019-02-03-20-23-30-000030\n",
      "    Last Checkpoint: AN4/chkpt/2019-02-03-17-47-37-000037/2019-02-03-20-23-30-000030/state.tar\n",
      "\n",
      "2019-02-03 20:23:31,140 | INFO : Training end.\n"
     ]
    }
   ],
   "source": [
    "H.MODEL_NAME = 'AN4_SPEECH_ENCODER_DECODER_2nd'\n",
    "H.PRELOAD_MODEL_PATH = 'AN4_SPEECH_ENCODER_DECODER_1st.tar'\n",
    "\n",
    "run_training(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 20:23:31,166 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 20:23:33,336 | INFO : Test Summary \n",
      "Bleu: 85.170\n",
      "WER:  6.903\n",
      "CER:  5.249\n",
      "ACC:  70.769\n"
     ]
    }
   ],
   "source": [
    "H.MODEL_NAME = 'AN4_SPEECH_ENCODER_DECODER_2nd'\n",
    "run_evaluation(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AudioDataset\n",
       "     Total of datapoints: 130\n",
       "     Total of duration (min): 5.949999999999999\n",
       "     Root Location: /Volumes/SSD1/AN4\n",
       "     Transforms: \n",
       "         AudioNormalizeDB(db=-40, max_gain_db=300)\n",
       "         AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
       "         AudioNormalize(mean=None, std=None)\n",
       "         FromNumpyToTensor(tensor_type=FloatTensor)\n",
       "     Label Transforms: \n",
       "         TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
       "         FromNumpyToTensor(tensor_type=LongTensor), 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_transform = transforms.Compose([\n",
    "                AudioNormalizeDB(db=H.NORMALIZE_DB, \n",
    "                                 max_gain_db=H.NORMALIZE_MAX_GAIN),\n",
    "                AudioSpectrogram(sample_rate=H.AUDIO_SAMPLE_RATE, \n",
    "                                 window_size=H.SPECT_WINDOW_SIZE, \n",
    "                                 window_stride=H.SPECT_WINDOW_STRIDE,\n",
    "                                 window=H.SPECT_WINDOW),\n",
    "                AudioNormalize(),\n",
    "                FromNumpyToTensor(tensor_type=torch.FloatTensor)\n",
    "                ])\n",
    "\n",
    "label_transform = transforms.Compose([\n",
    "                TranscriptEncodeSTS(vocab),\n",
    "                FromNumpyToTensor(tensor_type=torch.LongTensor)\n",
    "                ])\n",
    "\n",
    "test_dataset = AudioDataset(os.path.join(H.ROOT_DIR, H.EXPERIMENT), manifests_files=H.MANIFESTS, datasets=\"test\",\n",
    "                            transform=audio_transform, label_transform=label_transform, max_data_size=None, \n",
    "                            sorted_by='recording_duration')\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=H.BATCH_SIZE, num_workers=H.NUM_WORKERS, \n",
    "                                          shuffle=False, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "test_dataset, len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = NeuralSpeechRecognizer(vocab, test_loader.dataset.max_seq_length, rnn_hidden_size=H.RNN_HIDDEN_SIZE,\n",
    "                               rnn_num_layers=H.RNN_NUM_LAYERS, rnn_dropout=H.RNN_DROPOUT, cnn_dropout=H.CNN_DROPOUT,\n",
    "                               teacher_forcing_ratio=H.TEACHER_FORCING_RATIO,\n",
    "                               sample_rate=H.AUDIO_SAMPLE_RATE, window_size=H.SPECT_WINDOW_SIZE,\n",
    "                               initialize=torch_weight_init)\n",
    "if H.USE_CUDA:\n",
    "    model_pred.cuda()\n",
    "\n",
    "state = torch.load(os.path.join(H.EXPERIMENT, H.MODEL_NAME + '.tar'))\n",
    "model_pred.load_state_dict(state)\n",
    "\n",
    "criterion = LabelSmoothingLoss(padding_idx=0, label_smoothing=0.1)\n",
    "\n",
    "sts_decoder = STSDecoder(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 130)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.dataloader.audio import AudioDataset, BucketingSampler, collate_fn, DummyDataset, dummy_collate_fn\n",
    "\n",
    "test_path = './data/AN4/test/wav/*.wav'\n",
    "\n",
    "import glob\n",
    "audio_files = glob.glob(test_path)\n",
    "\n",
    "audio_transform = transforms.Compose([\n",
    "                AudioNormalizeDB(db=H.NORMALIZE_DB, \n",
    "                                 max_gain_db=H.NORMALIZE_MAX_GAIN),\n",
    "                AudioSpectrogram(sample_rate=H.AUDIO_SAMPLE_RATE, \n",
    "                                 window_size=H.SPECT_WINDOW_SIZE, \n",
    "                                 window_stride=H.SPECT_WINDOW_STRIDE,\n",
    "                                 window=H.SPECT_WINDOW),\n",
    "                AudioNormalize(),\n",
    "                FromNumpyToTensor(tensor_type=torch.FloatTensor)\n",
    "                ])\n",
    "\n",
    "dummy_dataset = DummyDataset(audio_files, H.AUDIO_SAMPLE_RATE, vocab, transform=audio_transform)\n",
    "\n",
    "dummy_loader = torch.utils.data.DataLoader(dummy_dataset, batch_size=H.BATCH_SIZE, \n",
    "                                           num_workers=H.NUM_WORKERS, shuffle=False, \n",
    "                                           collate_fn=dummy_collate_fn, pin_memory=True)\n",
    "\n",
    "recognizer = Recognizer(model_pred, sts_decoder, dummy_loader, probabilities=True)\n",
    "\n",
    "hypotheses = recognizer()\n",
    "\n",
    "idxs = []\n",
    "for data in dummy_loader:\n",
    "    idxs.extend(data[2])    \n",
    "    \n",
    "audio=[]\n",
    "for i in idxs:\n",
    "    audio.append(dummy_dataset.audio_files[i])\n",
    "      \n",
    "len(hypotheses), len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 20:23:36,025 | INFO : Creating pseudo dataset in root dir: /Volumes/SSD1/AN4\n",
      "2019-02-03 20:23:36,355 | INFO : Creation completed - manifest file: /Volumes/SSD1/AN4/sts_manifest_pseudo.json\n",
      "2019-02-03 20:23:36,356 | INFO : Total Entries: 130\n",
      "2019-02-03 20:23:36,357 | INFO : ... done.\n"
     ]
    }
   ],
   "source": [
    "from lib.datasets.an4 import create_manifest, create_pseudo_manifest, create_data_pipelines\n",
    "\n",
    "root_path = os.path.join('.', H.ROOT_DIR, H.EXPERIMENT)\n",
    "\n",
    "create_pseudo_manifest(root_path, audio, hypotheses, manifest_file='sts_manifest_pseudo.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 20:23:36,371 | INFO : Training start.\n",
      "2019-02-03 20:23:36,373 | INFO : {\n",
      "    'EXPERIMENT'                    : 'AN4' ,\n",
      "    'DESCRIPTION'                   : 'Sequence To Sequence model' ,\n",
      "    'TIMESTAMP'                     : '2019-02-03-17-47-37-000037' ,\n",
      "    'MODEL_NAME'                    : 'AN4_SPEECH_ENCODER_DECODER_final1' ,\n",
      "    'PRELOAD_MODEL_PATH'            : 'AN4_SPEECH_ENCODER_DECODER_2nd.tar' ,\n",
      "    'ROOT_DIR'                      : '/Volumes/SSD1' ,\n",
      "    'MANIFESTS'                     : ['manifest.json', 'sts_manifest_pseudo.json'] ,\n",
      "    'TARGET_ENCODING'               : 'sts' ,\n",
      "    'BATCH_SIZE'                    : 20 ,\n",
      "    'NUM_WORKERS'                   : 8 ,\n",
      "    'RNN_HIDDEN_SIZE'               : 256 ,\n",
      "    'RNN_NUM_LAYERS'                : 2 ,\n",
      "    'RNN_DROPOUT'                   : 0.5 ,\n",
      "    'CNN_DROPOUT'                   : 0.5 ,\n",
      "    'BIDIRECTIONAL'                 : True ,\n",
      "    'LR'                            : 0.0003 ,\n",
      "    'LR_LAMBDA': lambda epoch: max(math.pow(0.78, math.floor((1 + epoch) / 200.0)), 0.01),\n",
      "    'WEIGHT_DECAY'                  : 0 ,\n",
      "    'MOMENTUM'                      : 0.9 ,\n",
      "    'NESTEROV'                      : True ,\n",
      "    'TEACHER_FORCING_RATIO'         : 0.5 ,\n",
      "    'LABEL_SMOOTHING'               : 0.2 ,\n",
      "    'MAX_GRAD_NORM'                 : 400 ,\n",
      "    'MAX_EPOCHS'                    : 200 ,\n",
      "    'STOPPING_PATIENCE'             : 80 ,\n",
      "    'CHECKPOINT_INTERVAL'           : 10 ,\n",
      "    'CHECKPOINT_RESTORE'            : False ,\n",
      "    'USE_CUDA'                      : True ,\n",
      "    'SEED'                          : 123456 ,\n",
      "    'DATASET_MEAN_STD'              : (0.060487103, 0.16884679) ,\n",
      "    'NORMALIZE_DB'                  : -40 ,\n",
      "    'NORMALIZE_MAX_GAIN'            : 300 ,\n",
      "    'MIN_MAX_AUDIO_DURATION'        : None ,\n",
      "    'MIN_MAX_TRANSCRIPT_LEN'        : None ,\n",
      "    'MIN_TRANSCRIPT_CONFIDENCE'     : 0.95 ,\n",
      "    'AUDIO_SAMPLE_RATE'             : 16000 ,\n",
      "    'SPECT_WINDOW_SIZE'             : 0.02 ,\n",
      "    'SPECT_WINDOW_STRIDE'           : 0.01 ,\n",
      "    'SPECT_WINDOW'                  : 'hamming' ,\n",
      "    'AUGMENTATION_PROBABILITY'      : 0.6 ,\n",
      "    'NOISE_BG_PROBABILITY'          : 0.4 ,\n",
      "    'NOISE_BG_LEVELS'               : (0.0, 0.5) ,\n",
      "    'NOISE_BG_DIR'                  : '/Volumes/SSD1/BACKGROUND_NOISE' ,\n",
      "    'AUDIO_PITCH_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_PITCH_PM'                : 4 ,\n",
      "    'AUDIO_SPEED_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_SPEED_LOW_HIGH'          : (0.9, 1.1) ,\n",
      "    'AUDIO_DYNAMIC_PROBABILITY'     : 0.4 ,\n",
      "    'AUDIO_DYNAMIC_LOW_HIGH'        : (0.5, 1.1) ,\n",
      "    'AUDIO_SHIFT_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_SHIFT_MIN_MAX'           : (-10, 10) ,\n",
      "    'AUDIO_NOISE_PROBABILITY'       : 0.4 ,\n",
      "    'AUDIO_NOISE_LEVELS'            : (0.0, 0.5) ,\n",
      "    'AUDIO_NOISE_COLORS'            : ['white', 'pink', 'blue', 'brown', 'violet'] ,\n",
      "}\n",
      "\n",
      "2019-02-03 20:23:36,382 | INFO : AudioDataset\n",
      "    Total of datapoints: 948\n",
      "    Total of duration (min): 42.438333333333425\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioAugmentation [\n",
      "   AudioNoiseInjection(probability=0.4, noise_levels=(0.0, 0.5), noise_dir/Volumes/SSD1/BACKGROUND_NOISE),\n",
      "   AudioNoiseGeneration(probability=0.4, noise_levels=(0.0, 0.5), noise_colors['white', 'pink', 'blue', 'brown', 'violet']),\n",
      "   AudioPitchShift(probability=0.4, sample_rate=16000, pitch_pm=4),\n",
      "   AudioTimeStrech(probability=0.4, low_high=(0.9, 1.1)),\n",
      "   AudioDynamicRange(probability=0.4, low_high=(0.5, 1.1)),\n",
      "   AudioTimeShift(probability=0.4, sample_rate=16000, min_max=(-10, 10))\n",
      "], probability=0.6)\n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 20:23:36,389 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 20:23:36,390 | INFO : AudioDataset\n",
      "    Total of datapoints: 948\n",
      "    Total of duration (min): 42.438333333333425\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioAugmentation [\n",
      "   AudioNoiseInjection(probability=0.4, noise_levels=(0.0, 0.5), noise_dir/Volumes/SSD1/BACKGROUND_NOISE),\n",
      "   AudioNoiseGeneration(probability=0.4, noise_levels=(0.0, 0.5), noise_colors['white', 'pink', 'blue', 'brown', 'violet']),\n",
      "   AudioPitchShift(probability=0.4, sample_rate=16000, pitch_pm=4),\n",
      "   AudioTimeStrech(probability=0.4, low_high=(0.9, 1.1)),\n",
      "   AudioDynamicRange(probability=0.4, low_high=(0.5, 1.1)),\n",
      "   AudioTimeShift(probability=0.4, sample_rate=16000, min_max=(-10, 10))\n",
      "], probability=0.6)\n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 20:23:36,392 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 20:23:36,506 | INFO : Summary for model: NeuralSpeechRecognizer\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Shape                                   Param #        \n",
      "====================================================================================================\n",
      "cnn.conv1.seq_module.0 (Conv2d)              ((32, 1, 41, 11),)                      14432          \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.1 (BatchNorm2d)         ((32,), (32,))                          64             \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.2 (Hardtanh)            ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv1.seq_module.3 (Dropout)             ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.0 (Conv2d)              ((32, 32, 21, 11),)                     236544         \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.1 (BatchNorm2d)         ((32,), (32,))                          64             \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.2 (Hardtanh)            ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "cnn.conv2.seq_module.3 (Dropout)             ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "enc.rnn.rnn (GRU)                            ((768, 1312), (768, 256), (768,), (768, 3594240        \n",
      "____________________________________________________________________________________________________\n",
      "dec.embedding.0 (Embedding)                  ((32, 512),)                            16384          \n",
      "____________________________________________________________________________________________________\n",
      "dec.embedding.1 (Dropout)                    ()                                      0              \n",
      "____________________________________________________________________________________________________\n",
      "dec.attn.linear_out (Linear)                 ((512, 1024), (512,))                   524800         \n",
      "____________________________________________________________________________________________________\n",
      "dec.rnn (GRU)                                ((1536, 512), (1536, 512), (1536,), (15 3151872        \n",
      "____________________________________________________________________________________________________\n",
      "dec.fc (Linear)                              ((32, 512), (32,))                      16416          \n",
      "====================================================================================================\n",
      "Total params:         7,555,840\n",
      "Trainable params:     7,555,840\n",
      "____________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 20:23:36,587 | INFO : Preloaded model: AN4/AN4_SPEECH_ENCODER_DECODER_2nd.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n",
      "SIGINT received. Delaying KeyboardInterrupt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 21:09:28,672 | INFO : Training interrupted at: 100\n",
      "2019-02-03 21:09:28,930 | INFO : TensorboardLogger\n",
      "    Last Epoch/LR:    100 / 0.0003\n",
      "    Train Loss/Score: 0.9308745736562754 / 0.9687570897222796\n",
      "    Valid Loss/Score: 8.466199464064378 / 0.9184221227490458\n",
      "    Best Epoch/Score: 97 / 0.9270190279805665\n",
      "\n",
      "2019-02-03 21:09:28,931 | INFO : Stopping\n",
      "    Patience: 80\n",
      "    Best Score: 0.9270\n",
      "    Epoch of Best Score: 97\n",
      "\n",
      "2019-02-03 21:09:28,932 | INFO : Checkpoint\n",
      "    Timestamp: 2019-02-03-21-09-28-000028\n",
      "    Last Checkpoint: AN4/chkpt/2019-02-03-17-47-37-000037/2019-02-03-21-09-28-000028/state.tar\n",
      "\n",
      "2019-02-03 21:09:28,933 | INFO : Training end.\n"
     ]
    }
   ],
   "source": [
    "H.MODEL_NAME = 'AN4_SPEECH_ENCODER_DECODER_final1'\n",
    "H.PRELOAD_MODEL_PATH = 'AN4_SPEECH_ENCODER_DECODER_2nd.tar'\n",
    "        \n",
    "H.MANIFESTS = ['manifest.json','sts_manifest_pseudo.json']\n",
    "H.MIN_TRANSCRIPT_CONFIDENCE = 0.95\n",
    "H.AUGMENTATION_PROBABILITY = 0.6\n",
    "\n",
    "run_training(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-03 21:09:28,958 | INFO : AudioDataset\n",
      "    Total of datapoints: 130\n",
      "    Total of duration (min): 5.949999999999999\n",
      "    Root Location: /Volumes/SSD1/AN4\n",
      "    Transforms: \n",
      "        AudioNormalizeDB(db=-40, max_gain_db=300)\n",
      "        AudioSpectrogram(sample_rate=16000, window_size=0.02, window_stride=0.01, window=hamming)\n",
      "        AudioNormalize(mean=None, std=None)\n",
      "        FromNumpyToTensor(tensor_type=FloatTensor)\n",
      "    Label Transforms: \n",
      "        TranscriptEncodeSTS(vocab=_'ABCDEFGHIJKLMNOPQRSTUVWXYZ <SOS><EOS><UNK>)\n",
      "        FromNumpyToTensor(tensor_type=LongTensor)\n",
      "2019-02-03 21:09:31,144 | INFO : Test Summary \n",
      "Bleu: 83.770\n",
      "WER:  7.529\n",
      "CER:  5.735\n",
      "ACC:  72.308\n"
     ]
    }
   ],
   "source": [
    "run_evaluation(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
